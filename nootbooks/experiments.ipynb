{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "from policy import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(train_dataset, test_dataset, batch_size):\n",
    "    \n",
    "    train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=len(test_dataset))\n",
    "    \n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "def get_rewards_vector(full_rewards, actions):\n",
    "    actions_one_hot = F.one_hot(actions.long(), num_classes=full_rewards.size()[1]).float()\n",
    "    r = torch.matmul(full_rewards.unsqueeze(1), actions_one_hot.unsqueeze(2)).squeeze()\n",
    "    return r\n",
    "\n",
    "def snips_loss(pi_w, pi_0, r, lamda):\n",
    "    return torch.mean((1-r) * pi_w / pi_0) / torch.mean(pi_w / pi_0)\n",
    "\n",
    "def banditnet_loss(pi_w, pi_0, r, lamda):\n",
    "    return torch.mean(((1-r) - lamda) * (pi_w / pi_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(model, optimizer, train_dataloader, test_dataloader, n_epochs, loss_func, lamda=0.9, model_name='temp'):\n",
    "    \n",
    "    train_losses = []\n",
    "    test_values = []\n",
    "    test_accuracies = []\n",
    "    best_value = 0\n",
    "    \n",
    "    for t in tqdm(range(n_epochs)):\n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "        model.train()\n",
    "        tol_loss = 0\n",
    "        \n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            \n",
    "            data = [i.to(device) for i in data]\n",
    "            X, actions, pi_0, y, full_rewards = data\n",
    "            \n",
    "            pi_w = model.get_action_propensities(X, actions)\n",
    "            r = get_rewards_vector(full_rewards, actions)\n",
    "            loss = loss_func(pi_w, pi_0, r, lamda=lamda)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            tol_loss += loss\n",
    "        \n",
    "        train_losses.append(tol_loss/len(train_dataloader))\n",
    "        \n",
    "        # ========================================\n",
    "        #               Testing\n",
    "        # ========================================\n",
    "        model.eval()\n",
    "        X_test, y_test, full_rewards_test = test_dataloader.dataset.tensors\n",
    "        X_test = torch.FloatTensor(X_test).to(device)\n",
    "        full_rewards_test = torch.FloatTensor(full_rewards_test).to(device)\n",
    "        \n",
    "        # value\n",
    "        value = model.get_value_estimate(X_test, full_rewards_test).item()\n",
    "        \n",
    "        # deterministic accuracy\n",
    "        y_pred = torch.argmax(model.get_action_distribution(X_test), dim=1)\n",
    "        accuracy = (y_pred.cpu().detach().numpy() == y_test.cpu().detach().numpy()).sum() / len(y_test)\n",
    "        \n",
    "        test_values.append(value)\n",
    "        test_accuracies.append(accuracy)        \n",
    "        \n",
    "        # check if test value is increasing\n",
    "        if value > best_value:\n",
    "            torch.save(model, f'../models/{model_name}.pt')\n",
    "            best_value = value\n",
    "\n",
    "    return train_losses, test_values, test_accuracies, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.load('../data/train_dataset.pt')\n",
    "test_dataset = torch.load('../data/test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size:  64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f0032c14824cd9b6848ae5d4efc690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BanditNet Value:  0.17206531763076782\n",
      "BanditNet Accuracy:  0.1735\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7c003e20d546c6b341a422809603a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SNIPS Value:  0.1353093981742859\n",
      "SNIPS Accuracy:  0.13575\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Batch Size:  128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df29bd1a62954326b9d936203b9fb5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BanditNet Value:  0.10615689307451248\n",
      "BanditNet Accuracy:  0.10675\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62519e335f1042cda9bff5474c9e5bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SNIPS Value:  0.13924174010753632\n",
      "SNIPS Accuracy:  0.13875\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Batch Size:  256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7005e954e0774e3e928cff049fa48bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BanditNet Value:  0.13264243304729462\n",
      "BanditNet Accuracy:  0.133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6781bc6668449e2bb09bf559d006067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SNIPS Value:  0.07123489677906036\n",
      "SNIPS Accuracy:  0.0715\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Batch Size:  512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a833cf368f74fa0988b376c87f20ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BanditNet Value:  0.19758711755275726\n",
      "BanditNet Accuracy:  0.1995\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fad79750bf24969a138a71df849dd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SNIPS Value:  0.10518762469291687\n",
      "SNIPS Accuracy:  0.106\n",
      "==================================================\n",
      "\n",
      "\n",
      "\n",
      "Batch Size:  1024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb5b198f53042a2861af17c4bbcfa8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BanditNet Value:  0.07706692814826965\n",
      "BanditNet Accuracy:  0.07725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372240cd494e42aa8ec6ed8be30511bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2bdce11f800b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     SNIPS_results = train_loop(model, optimizer, train_dataloader, test_dataloader, n_epochs=n_epochs, \n\u001b[0m\u001b[0;32m     59\u001b[0m                                loss_func=loss_func, model_name=model_name)\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-2938342dfd15>\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(model, optimizer, train_dataloader, test_dataloader, n_epochs, loss_func, lamda, model_name)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256, 512, 1024, 2048, 4096]\n",
    "lr = 0.1\n",
    "n_epochs = 50\n",
    "model_dir = '../models/'\n",
    "\n",
    "X_test, y_test, full_rewards_test = test_dataset.tensors\n",
    "X_test = torch.FloatTensor(X_test).to(device)\n",
    "full_rewards_test = torch.FloatTensor(full_rewards_test).to(device)\n",
    "BN_values = []\n",
    "BN_accuracies = []\n",
    "SNIPS_values = []\n",
    "SNIPS_accuracies = []\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    print('Batch Size: ', batch_size)\n",
    "    \n",
    "    # get dataloaders\n",
    "    train_dataloader, test_dataloader = get_dataloaders(train_dataset, test_dataset, batch_size=64)\n",
    "    \n",
    "    #===========================\n",
    "    #   BanditNet\n",
    "    #===========================\n",
    "    loss_func = banditnet_loss\n",
    "    model_name = f'{batch_size}-BanditNet'\n",
    "    \n",
    "    model = LogisticPolicy(num_actions=26, num_features=16)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    BN_results = train_loop(model, optimizer, train_dataloader, test_dataloader, n_epochs=n_epochs, \n",
    "                            loss_func=loss_func, model_name=model_name)\n",
    "    \n",
    "    ## load best model\n",
    "    model = torch.load(model_dir + f'{model_name}.pt')\n",
    "    model = model.to(device)\n",
    "    ## value\n",
    "    value = model.get_value_estimate(X_test, full_rewards_test).item()\n",
    "    \n",
    "    ## deterministic accuracy\n",
    "    y_pred = torch.argmax(model.get_action_distribution(X_test), dim=1)\n",
    "    accuracy = ((y_pred.cpu().detach().numpy() == y_test.cpu().detach().numpy()).sum() / len(y_test)).item()\n",
    "    \n",
    "    BN_values.append(value)\n",
    "    BN_accuracies.append(accuracy)\n",
    "    \n",
    "    print('BanditNet Value: ', value)\n",
    "    print('BanditNet Accuracy: ', accuracy)\n",
    "    \n",
    "    #===========================\n",
    "    #   SNIPS\n",
    "    #===========================\n",
    "    loss_func = snips_loss\n",
    "    model_name = f'{batch_size}-SNIPS'\n",
    "    \n",
    "    model = LogisticPolicy(num_actions=26, num_features=16)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    SNIPS_results = train_loop(model, optimizer, train_dataloader, test_dataloader, n_epochs=n_epochs, \n",
    "                               loss_func=loss_func, model_name=model_name)\n",
    "    \n",
    "    ## load best model\n",
    "    model = torch.load(model_dir + f'{model_name}.pt')\n",
    "    \n",
    "    ## value\n",
    "    value = model.get_value_estimate(X_test, full_rewards_test).item()\n",
    "    \n",
    "    ## deterministic accuracy\n",
    "    y_pred = torch.argmax(model.get_action_distribution(X_test), dim=1)\n",
    "    accuracy = ((y_pred.cpu().detach().numpy() == y_test.cpu().detach().numpy()).sum() / len(y_test)).item()\n",
    "    \n",
    "    SNIPS_values.append(value)\n",
    "    SNIPS_accuracies.append(accuracy)\n",
    "    \n",
    "    print('SNIPS Value: ', value)\n",
    "    print('SNIPS Accuracy: ', accuracy)\n",
    "    print('='*50)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    \n",
    "# Save results to a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Batch_Size': batch_sizes,\n",
    "    'BanditNet_Value': BN_values,\n",
    "    'BanditNet_Accuracy': BN_accuracies,\n",
    "    'SNIPS_Value': SNIPS_values,\n",
    "    'SNIPS_Accuracy': SNIPS_accuracies\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch_Size</th>\n",
       "      <th>BanditNet_Value</th>\n",
       "      <th>BanditNet_Accuracy</th>\n",
       "      <th>SNIPS_Value</th>\n",
       "      <th>SNIPS_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.040754</td>\n",
       "      <td>0.04075</td>\n",
       "      <td>0.042560</td>\n",
       "      <td>0.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.039759</td>\n",
       "      <td>0.03975</td>\n",
       "      <td>0.036672</td>\n",
       "      <td>0.0365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch_Size  BanditNet_Value  BanditNet_Accuracy  SNIPS_Value  \\\n",
       "0          64         0.040754             0.04075     0.042560   \n",
       "1         128         0.039759             0.03975     0.036672   \n",
       "\n",
       "   SNIPS_Accuracy  \n",
       "0          0.0425  \n",
       "1          0.0365  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
